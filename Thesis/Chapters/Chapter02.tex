%%% Local Variables:
%%% mode: latex
%%% TeX-master: "classicthesis"
%%% End:
\chapter{A Second Attempt}\label{ch:SecondAttempt}

In seeking a more general theory, the functional calculus defined last chapter
is insufficient---it would be useful to be able to define \emph{new} functions
instead of simply lifting polynomials to matrix domains. In a move that will
feel familiar to any good student of mathematics, we will treat the
set of self-adjoint matrices and nc polynomials
as prototypical examples of a more general mathematical
object, the so-called \emph{Matrix Universe}.
After defining this new space and the natural maps in
\cref{sec:MatUniv,sec:TracGrad}, we turn our attention to various topologies
placed on matrix universes in \cref{sec:TopManUniv}. While the beginnings of
modern free
analysis followed \cref{ch:FirstAttempt} (albeit with the usual bumps in the
road that accompany research), contemporary free analysis looks much more like this
chapter.

\section{Matrix Universes}%
\label{sec:MatUniv}

Beyond the functional calculus, it becomes useful to construct general functions
on spaces of matrices---to do so, we must make this idea of ``spaces of
matrices'' concrete. The largest such space is the so-called \textbf{Matrix
  Universe}---consisting of \(g\)-tuples of matrices of all sizes:
\[
  \MM^g := \bigcup_{n=1}^\infty (M_n(\CC))^g
\]
By convention, when we consider some
\(X = \left( X_1, \dots , X_g \right) \in \MM^g\), we require that the \(X_i\)
are all the same size. Since \(\MM^g\) is such a large set, we often want to
deal with subsets that still carry some of the implicit structure of \(\MM^g\).
\begin{definition}[Free Set]
  \label{def:FreeSet}
  We say \(D \subset \MM^g\) is a \textbf{free set} (also called an nc set) if it is closed with respect
  to direct sums and unitary conjugation. That is
  \begin{enumerate}
    \item \(X,Y \in D \) means \(X\oplus Y \in D\).
    \item For \(X,U\) like-size matrices with \(U\) unitary and \(X \in D\),
          then \(U X U^* = \left( UX_1U^*, \dots , UX_g U^*  \right) \in D \).
  \end{enumerate}
\end{definition}

For the remainder of this text, \(D\) will denote some free set. Using the
terminology of \cite{pascoeFreeNoncommutativePrincipal2020}, let
\(D_n = D \cap M_n(\CC)^g\) be the level-wise slice of all \(n \times n\)
matrices in \(D\). We say that \(D\) is \textbf{nc open}\footnote{The topology of \(\MM^g\)
  is still in flux and there is not a canonical topology. See section \ref{sec:TopManUniv} for
  the details } (resp.\ \textbf{connected}, \textbf{simply connected}, \textbf{bounded}) if each \(D_n\) is open
(resp.\ connected, simply connected, bounded). An \textbf{nc domain} is an open,
connected free set. Finally, we say that \(D\) is
\textbf{differentiable} if each \(D_n\) is an open \(C^1\) manifold where the
complex tangent space of every \(X \in D_n\) is all of \(M_n(\CC)^g\).
Given some \(X \in \MM^{g} \), there are three associated sets which capture the
structure of free sets.

\begin{definition}[Similarity Envelope]%
\label{def:semenv}
  Given \(X \in \MM^{g} \), a tuple of \(n \times n\) matrices, the
  \textbf{similarity envelope} of \(X\) is the set
  \[
    \{U^* X U \mid  U \in \mathcal{U}_n\}.
  \]
\end{definition}

\begin{definition}[Fiber]%
\label{def:fiber}
  Given \(X \in \MM^{g} \), a tuple of \(n \times n\) matrices, the
  \textbf{fiber} of \(X\) is the set
  \[
    \{X^{\oplus k} \mid  k \in \NN \}.
  \]
\end{definition}

\begin{definition}[Envelope]%
\label{def:env}
  Given \(X \in \MM^{g} \), a tuple of \(n \times n\) matrices, the
  \textbf{envelope} of \(X\) is the set
  \[
    \{ U^* X^{\oplus k} U \mid k \in \NN, U \in \mathcal{U}_{kn} \}.
  \]
\end{definition}
Notice that if \(X \in D\), then the entire envelope of \(X\) is automatically
in \(D\) as well! Further, as shown in example \ref{ex:multivareval},
polynomials respect the envelope of a matrix in a particularly well-behaved way.
Colloquially, we think of all points in the envelope of \(X\) as ``the
same''---this notion is explored in section \ref{sec:TopManUniv} and throughout
chapter \ref{ch:monodromy}.

In the context of \cref{sec:functionalcalc,sec:ExtMuliVarFun}
%
, the domains in the functional calculus was the self adjoint matrix universe:
\(\HH^g = \bigcup_{n=1}^{\infty} {\HH_n}^g\). \(\HH ^g\) is a differentiable, connected
free set.

On \(\MM^{g} \), we define a product that resembles the inner product on
\(\CC^n\) which will be used extensively throughout \cref{ch:ZeroDiv,ch:monodromy}.
Given \(A,B \in \MM^{g} \) which are \(g\)-tuples of \(n \times n\) matrices:
\begin{align*}
	\cdot : \MM^{g} \times \MM^{g}  &\longrightarrow M_n(\CC) \\
  \cdot (A,B) = A \cdot B &\longmapsto \sum_{i=1}^g A_i B_i
\end{align*}

If we combine this product with the trace, we get a bilinear form on
\(\MM^{g} \) which functions like an inner product given by \(\tr(A \cdot B)\).
It will be particularly useful in \cref{ch:monodromy} as well as for defining the
gradient of a function.


\section{Tracial Functions and Uniqueness of the Gradient}%
\label{sec:TracGrad}
Now that we have \(\MM^d\), we can work with general functions on our matrix
universe. As a whole, free analysis is concerned with so-called \emph{free
  functions}, which are graded and
respect direct sums and unitary conjugation.

\begin{definition}[Free Function]
\label{def:FreeFun}
  A function \(f: D\to \MM^{\hat{d}}\) is called \textbf{free} if
  \begin{enumerate}
    \item \(f(X\oplus Y)= f(X) \oplus f(Y)\)
    \item \(f(U X U^*) = f(U)f(X)f(U^*)\) where \(X\) and \(U\) are like-size
          and \(U\) is unitary.
  \end{enumerate}
\end{definition}

Before moving on to the other classes of functions on \(\MM^{g}\), it is worth
noting that free functions are defined in this way \emph{precisely because}
polynomials have this same behavior. Free functions, then, are those which
behave like polynomials with respect to the implicit structure of free sets.
The two other classes of functions we are concerned with are those which act like
the trace and the determinant:
\begin{definition}[Determinantal Free Function]%
\label{def:DetFreeFun}
  A function \(f: D \to \CC \) is a \textbf{determinantal free function} if
  \begin{enumerate}
    \item \(f(X\oplus Y) = f(X)f(Y)\)
    \item \(f(U X U^*) = f(X)\) where \(X\) and \(U\) are like-size
          and \(U\) is unitary.
  \end{enumerate}
\end{definition}

\begin{definition}[Tracial Free Function]%
\label{def:TrFreeFun}
  A function \(f: D \to \CC \) is a \textbf{tracial free function} if
  \begin{enumerate}
    \item \(f(X\oplus Y) = f(X)+f(Y)\)
    \item \(f(U X U^*) = f(X)\) where \(X\) and \(U\) are like-size
          and \(U\) is unitary.
  \end{enumerate}
\end{definition}

It is worth noting that, while they share the moniker of \emph{free},
determinantal and tracial functions are \emph{not} free functions.
Since these three classes of functions all contain the word ``free,'' we will
often drop this qualifier and only refer to determinantal, tracial, and free
functions.  For any of theses functions, we can define the directional
derivative (Definition \ref{def:DirDeriv}) identically, however, it is only tracial functions which inherit
the gradient mentioned \cref{sec:functionalcalc}. Similarly to traditional multivariable calculus
we define the gradient via its relationship to the directional derivative:
\begin{definition}[Free Gradient]%
\label{def:FreeGrad}
  Given a tracial free function \(f\), the free gradient, \(\nabla f\), is the
  unique free function satisfying
  \[
    \tr \left( H \cdot \nabla f(X) \right) = Df(X)[H].
  \]
\end{definition}

It is not-at-all obvious that such a \(\nabla f \) should be unique---after all
any linear combination of commutators has trace zero. To show the uniqueness of
\(\nabla f\), we will first restrict ourselves to single variable functions. In the case that \(f\)
is a single-variable function we can replace \(\nabla f\) with the traditional
derivative, \(f'\), as seen in
\cite[Thm 3.3]{pascoeTrace2020}.
\begin{theorem}
  Let \(f: (a,b)\to \RR \) be a \(C^1\) function. Then (in the functional
  calculus of \cref{sec:functionalcalc})
  \[
    \tr \, Df(X)[H] = \tr \left( Hf'(X) \right).
  \]
\end{theorem}

The proof in \cite{pascoeTrace2020} simply asserts the uniqueness of a function
\(g(X)\) satisfying \(\tr Df(X)[H] = \tr(Hg(X))\) and then shows that
\(g(x)=f'(x)\) for \(x \in (a,b)\). Instead, we can construct such a \(g\) and
recover the theorem along the way:
\begin{proof}

We start with a construction from Bhatia's Matrix Analysis \cite{bhatiaMatrixAnalysis1997}: Let
$f \in C ^{1} (I)$ and define $f ^{[1]} $ on $I \times I$ by
\[
  f^{[1]} (\lambda,\mu) =
  \begin{cases}
    \frac{f(\lambda) - f(\mu)}{\lambda-\mu} & \lambda \neq \mu \\
    f'(\lambda) & \lambda = \mu.
  \end{cases}
\]
We call $f ^{[1]} (\lambda,\mu)$ the \emph{first divided difference} of $f$ at
$(\lambda,\mu)$. If $\Lambda$ is a diagonal matrix with entries
$\{ \lambda_{i}\} $, we may extend $f$ to accept $\Lambda$ by
defining the $(i,j)$-entry of $f ^{[1]} (\Lambda)$ to be
$f ^{[1]} (\lambda_i,\lambda_j)$. If $A$ is a self adjoint matrix with
$A = U \Lambda U ^{*} $, then we define
$f ^{[1]} (A) = U f ^{[1]} (\Lambda) U ^{*} $. Now we borrow a theorem from
Bhatia:
\begin{theorem}[Bhatia V.3.3]
  Let $f \in C ^{1} (I)$ and let $A$ be a self adjoint matrix with all
  eigenvalues in $I$. Then \[
    Df(A)[H] = f ^{[1]} (A) \circ H,
  \]
  where $\circ$ denotes the Schur-product\footnote{Entrywise} in a basis where $A$ is diagonal.
\end{theorem}

That is, if $A = U   \Lambda U ^{*} $, then
\[
  Df(A)[H] = U \left( f ^{[1]} (\Lambda) \circ (U ^{* } H U) \right)U ^{*}.
\]
%
To prove our claim, we need to take the trace of both sides. Since trace is
invariant under a change of basis, it is clear that
\[
  \tr Df(A)[H] = \tr \left( f ^{[1]} (\Lambda) \circ (U ^{* } H U) \right).
\]
If $U = u_{ij}$, $U ^{*} = \overline{u}_{ij}$ and $H = h_{ij}$, then the
$(i,j)$-entry of $U ^{*}HU$ is
\[
  {(U ^{* } H U)}_{ij} = \sum_k\sum_\ell \overline{u}_{ik}h_{k\ell}u_{\ell j}.
\]
While the structure of
$f ^{[1]} (\Lambda)$ is a bit unruly, our diagonal entries are $f'(\lambda)$.
This means that when we take the trace of the Schur product, we have
\[
 \sum_k\sum_\ell \sum_i f'(\lambda_i)\overline{u}_{ik}h_{k\ell}u_{\ell i}.
\]
Now consider the matrix product
$U\, \text{diag} \{f'(\lambda_1), \dots ,f'(\lambda_n)\} \,U ^{*} H $. Since one of our terms
is diagonal, the trace of this multiplication is simple:
\[
  \text{tr}\; U \,\text{diag} \{f'(\lambda_1), \dots ,f'(\lambda_n)\}\, U ^{*} H
  = \sum_k\sum_\ell\sum_i  u_{ik}f'(\lambda_k) \overline{u}_{k \ell} h_{\ell i}
\]
Since \(u_{ik}, \overline{u}_{k\ell}, h_{\ell i} \in \CC \) they commute. We can
then relabel our indices
$i \mapsto \ell\; \ell \mapsto k \; k \mapsto i $ to get
\[
  \tr\; U \,\text{diag} \{f'(\lambda_1), \dots ,f'(\lambda_n)\}\, U ^{*} H
  = \sum_k\sum_\ell \sum_i f'(\lambda_i) \overline{u}_{i k} h_{k \ell}u_{\ell i},
\]
So, for every direction \(H\), we have that
\[
  \tr \left( U\, \text{diag} \{f'(\lambda_1), \dots ,f'(\lambda_n)\} \,U ^{*} H\right) =
  \tr \left( f ^{[1]} (\Lambda) \circ (U ^{* } H U) \right).
\]
By picking the ``correct'' \(H\),
\footnote{See the proof of \ref{thm:trdual} for the details of how to pick the
  \(H\)'s}
we conclude that there is a unique quantity \(g(X)\) satisfying
\[
  \tr \;Df(X)[H] = \tr(Hg(X)).
\]
In particular,
\( g(X) = U\, \text{diag} \{f'(\lambda_1), \dots ,f'(\lambda_n)\} \,U ^{*} \). But,
recall that \(X=U\Lambda U\) so, in the functional calculus, $g(X) = f'(X)$.
Making this substitution, we have the required result:
\[
  \tr \; Df(X)[H] = \tr (H f'(X)).
\]
\end{proof}

With our theorem proven, we turn our attention back to the \(\nabla f\). The
single variable case motivates that \(\nabla f\) should correspond to the
standard gradient from vector calculus. With some work, the above proof lifts
the multi-variable case.

The careful reader will note that the above theorem (even if lifted to the
multivariable case) does not immediately give us the uniqueness of
\(\nabla f\)---after all, the theorem requires free functions and that there
is a trace on both sides. Thankfully, both of these are fairly easy to deal
with. For the former objection is handed easily; since \(Df(X)[H]\) is a scalar
function, so adding a trace doesn't affect the equation. For the latter, we
present the following proof of ``trace duality.'' While the theorem still refers
to free functions, the technique of picking coordinate matrices is
standard\footnote{The technique is rarely \emph{used} in the literature. Instead
it is assumed that the reader can use the trick to verify statements which are
left unproven.}
and can be easily reused to show the uniqueness of \(\nabla f\).\footnote{If the
reader is still unconvinced, see the discussion of \(\tr (\;\;\cdot\;\;)\) as an
``inner product'' on \(\MM^{g} \) in \cref{sec:cohomo}.}

\begin{theorem}[Trace Duality]%
\label{thm:trdual}
Let \(f,g\) be free functions \(\MM^{g} \to \MM^{\tilde{g}} \). If
\(\tr (H \cdot f) = \tr (H \cdot g)\) for all tuples \(H\), then \(f=g\).
\end{theorem}

\begin{proof}
  Since the trace relation holds for all $H$, we may choose our $H$ carefully to
  show the equality of $f$ and $g$. Say that $H,f(X),g(X)$ are $g$-tuples of
  matrices---we will first show that $f_1=g_1$ and we will do so entry by entry.
  Let $E_{ij}$ be the matrix will all zeroes and a \(1\) in the $(i,j)$-entry.  Now
  let $H= (E_{ji},0, \dots ,0)$. So $\tr E_{ji}f_1(X) = \tr E_{ji}g_1(X)$.
  In our products, the only elements on the diagonal are $(f_1(X))_{ij}$ and
  $(g_1(X))_{ij}$, so when we take the trace we have $(f_1(X))_{ij} =(g_1(X))_{ij}$. If we
  do this for every $(i,j)$, we see that $f_1(X)=g_1(X)$. Similarly, we can choose
  \(H = ( 0, E_{ji},0, \dots, 0)\) for each \(i,j\) to show that \(f_2(X)=g_2(X)\) and
  so on. Since \(f(X)=g(X)\) for each \(X \in \MM^{g} \), it follows that \(f=g\).
\end{proof}

Admittedly, there is a slight complication that is overlooked in the above proof
when it comes to the domains of \(f\) and \(g\). Where these domains overlap, we
can consider them as the same function (and therefore \(\nabla f \) is unique)
but if \(f\) is defined on \(D\) and \(g\) is defined on \(\tilde{D}\), then the
above proof only holds on \(D \cap \tilde{D}\). This complication  occurs
semi-frequently in free analysis, but in general is swept under the rug---if two
free functions agree the intersection of their domains, it is convention to
consider them equivalent. Examples
of such \(f\) and \(g\) abound when considering rational functions, which are
explored in \cref{sec:ncrational}.

\section{The Topology of Matrix Universes }%
\label{sec:TopManUniv}

At the time of writing, there is no ``canonical topology'' for \(\MM^g\). For a
long time it seemed like the \emph{free} topology (to be defined below) was the
obvious choice, but recent work (c.f.\ \cite{pascoeentire2019}) has implied that the free
topology does not put enough structure on \(\MM^g\). See \cite{aglerAspects2016}
for a full treatment of the common topologies on \(\MM^g\).

A naive approach to a topology on \(\MM = \bigcup_n M_n(\CC)\) would be the
disjoint union topology---which is then extended do a topology on \(\MM^g\) via
the product topology. Notice, however that this ignores a significant amount of
the implicit structure of nc sets as we get a disconnected space with countable
many connected components. Topologically, this is means that means that
\[
  H_\bullet (D) = \bigoplus_{n \in \NN } H_\bullet(D_n).
\]
At first glance, this seems fine enough, but it ignores the fact that for
\(X \in D\) we require \(X^{\oplus k} \in D\) for all \(k\) and \(U^*XU \in D\)
for all unitary \(U\). In a sense, we think of the all the direct sums of \(X\)
and its similarity envelope as ``the same.'' In light of this, if \(\sim\) is
the equivalence relation that \(X\sim Y\) if \(Y = X^{\oplus k}\) or
\(Y = U^*XU\) ,
then any useful topological theory on \(D \subset \MM^g\) should descend to
classic theory on \(\faktor{D}{\sim}\). One needs only look at \(H_0(D)\) to see
that the naive approach fails to give useful information. It should be the case
that \(H_0(\MM^{g} )\) is \(\ZZ \) but in the disjoint union topology it is easy
to see
\[
  H_0(\MM^{g} ) = \bigoplus_{n \in \NN } \ZZ ,
\]
which does not behave as we would expect.


\subsection{Admissible Topologies}%
\label{sec:admtopo}

In light of the above discussion, we will present some of the candidate
topologies which show some promise in understanding the topology on \(\MM^g\)
and its subsets.
Let \(D \subset \MM^{g} \) be a nc bounded open set (recall that this means that \(D\) is closed under
direct sums and unitary conjugation, and that each \(D_n\) is a bounded open set
in \(M_n(\CC)^g\)) and let
\[
  \mathcal{B} = \{D \mid  D \textrm{ is an nc bounded open set}\} .
\]
It is not difficult to se that \(\mathcal{B}\) is the basis for a topology on
\(\MM^{g}\), called the \textbf{fine topology}. Currently, there is not a
``standard'' topology for \(\MM^{g}\). Any topology, \(\tau\), on \(\MM^{g}\) is
considered \textbf{admissable} if it basis is a subset of \(\mathcal{B}\)---\ie{}
it has a basis of nc bounded open sets.

\begin{example}%
\label{ex:context}
  The fine topology is often very convenient as we can leverage the level-wise
  open-ness of the basis. Let \(\mathbb{D} \subset \MM \) denote the set of
  diagonalizable matrices. We seek to show that \(\mathbb{D}\) is dense in
  \(\MM\). Let \(D \in \mathcal{B}\) be nonempty. Since \(D\) is open in
  \(\MM\), we know that \(D_n\) is open in \(M_n(\CC)\). But \(\mathbb{D}_n\) is
  dense in \(M_n(\CC)\), so \(D_n \cap \mathbb{D} \neq \emptyset\). It follows
  that \(D \cap \mathbb{D} \neq \emptyset\), and so \(\mathbb{D}\) is dense in
  \(\MM\).

  Of course, a similar argument works in \(\MM^{g} \). This gives an powerful
  boost to the functional calculi discussed in \cref{ch:FirstAttempt}. While we
  worked over the self adjoint matrices, one can develop a nearly identical
  functional calculus for diagonalizable matrices. Since the diagonalizable
  matrices are dense in \(\MM^{g} \), however, we obtain a function on the
  entire domain by via a continuous extension off of the diagonalizable
  matrices! This gives us a way to make sense of the free functions
  \[
    f(X,Y)=e^Xe^Y, \qquad g(X,Y)=e^{X+Y}
  \]
  both of which map \(\MM^{2} \to \MM\).
\end{example}

A slightly more restrictive topology (that seems to show some promise in the eyes
of the author) is the \textbf{fat topology}. For \(n \in \NN \),
\(r \in \RR ^+\), and \(X \in \MM^g_n\), we first define a matricial polydisc
\[
  D_n(X,r) := \{A \in \MM^g \mid \max_{1\leq i\leq g} \| X_i-A_i \| <r\}.
\]
Now we sweep \(D_n\) through all direct sum copies of \(X\):
\[
  D(X,r) := \bigcup_{k=1}^\infty D_{kn} (X^{\oplus k},r)
\]
Finally, we take the similarity envelope of \(D(X,r)\)
\[
  F(X,r) :=  \bigcup_{n=1}^\infty \bigcup_{U \in \mathcal{U}_n} U^* \left( D(X,r) \cap \MM^g_n \right) U
\]
Both the fine and the fat topologies admit implicit function theorems---which
are discussed (in brief) in \cref{sec:freeanal}.

The final candidate topology is the aforementioned \textbf{free topology}.
Recall that \(\RR \langle x \rangle \) is the algebra of nc polynomials over the
real numbers and that
\(\RR \langle x \rangle ^{k\times k}\) is the set of \(k \times k\) matrices
with entries in \(\RR \langle x \rangle \). Let
\(\delta \in \RR \langle x \rangle ^{k\times k}\) and define
\[
  G_\delta = \{x \in \MM^{g} \mid \| \delta(x) \| <1\}.
\]
For \(x \in M_n(\CC)\), \(\|\cdot \|\) is the operator norm in
\(\mathcal{B}(\CC^k\otimes\CC^n)\). This may seem strange
\footnote{The author would like to note that it is, in fact, strange.}
but the level-wise definition allows the norm to ``play nice'' with direct sums.
The set of all \(G_\delta\) as \(k\) ranges over \(\ZZ ^+\) form the basis for
the free topology. Indeed, any \(X \in \MM^{g} \) is trivially in one of the
\(G_\delta\) (take \(\delta=X\)) and with some work one can show that
\(G_{\delta_1} \cap G_{\delta_2}= G_{\delta_1\oplus \delta_2}\) so we do,
indeed, have a basis. All that is needed to satisfy the axioms for a base is that
\(G_{\delta_1} \cap G_{\delta_2} \supset G_{\delta_1\oplus \delta_2}\). In
fact if one chose a more ``standard'' norm for \(\delta(X)\) above (\eg the
Frobenius norm) one gets the needed inclusion. The benefit of the strange norm,
however, is that we get equality here instead of inclusion.

\section{Free Analogues of Classical Results}%
\label{sec:freeanal}

In general, efforts to reprove classical results from single and several variable
complex analysis have been successful. A full treatise of the results proven
before 2020 can be found in \cite{aglerOperator2019}---but we will include a
handful here.

Among the many astounding results is the following characterization of
holomorphic functions in admissible topologies:
\begin{theorem}[Locally Bounded Implies Analytic]
  Let \(D\) be an nc domain and \(f\) a free function on \(D\). If \(f\) is
  locally bounded on each \(D_n\), then \(f\) is an analytic function of the
  entries of the matrices at each level \(n\).
\end{theorem}
A proof for this (rather suprising) result is given in \cite{aglerAspects2016}.
With different topologies come different analytic functions. In light of this,
if the topology is not understood functions are usually referred to as
\{fine/fat/free\} holomorphic.
As mentioned above, both the fine and fat topologies have implicit function
theorems. The fat implicit function theorem requires a significant amount more
work to state, but it can be found in \cite{aglerOperator2019}.
\clearpage
\begin{theorem}[Fine Implicit Function Theorem]
  Let \(D \subset \MM^g\) be an nc domain. Let \(\Phi\) be a fine holomorphic
  map \(D\to \MM^{g} \). The following equivalent:
  \begin{enumerate}
    \item \(\Phi\) is injective on \(D\)
    \item \(D\Phi(X)[H]\) is nonsingular for every \(X \in D\) and like-size
          \(H \in \MM^{g}\).
    \item the function \(\Phi ^{-1}\) exists and is a fine holomorphic
          map.
  \end{enumerate}
\end{theorem}

Various Null- and Positivstellensatz
\footnote{And even a QuadratischePositivstellensatz!} exist throughout the
literature extending Hilbert's famous Nullstellensatz in algebraic
geometry---many of which utilize the idea of so-called ``atomic'' matrices of nc
polynomials (defined in \ref{def:atomic}). See \cite{heltonFactorization2019}
for the specifics.

In \cite{aglerGlobal2013}, Agler and McCarthy prove a free analogue of the
Oka-Weil theorem: any free holomorphic function on a compact set
can be uniformly approximated by polynomials. Unfortunately, it was later proven
in \cite{pascoeInvariant2021} and \cite{augatCompact2017} that the only compact
sets in the \(\MM^{g} \) are the envelope of finitely many points, which
substantially lessens the strength of
Agler and McCarthy's result.



\section{nc Rational Functions}%
\label{sec:ncrational}

While polynomials were fairly simply to lift to the noncommutative setting,
dealing with rational functions is a bit more complex. In depth discussion of nc
rational functions descends quickly into abstract nonsense, so we will only
cover the basics and will not go beyond what is needed for the work done in the
rest of this thesis.

\begin{definition}[nc Rational Expression]%
\label{def:ratexp}
  An \textbf{nc rational expression} (alternativey a free rational expression)
  in noncommuting indeterminants, \(x_1, \dots ,x_g\) is a syntactically valid
  expression of those indeterminants involving addition, multiplicatoin, inverses,
  and scalar multiplication.
\end{definition}

For example, the following are examples of free rational expressions in two
variables:
\begin{equation*}
\begin{split}
  x_1x_2+x_2x_1(x_1-x_2)^{-1} &,\; (2x_2^2x_1^{-1} +(x_1x_2-x_2x_1)^{-1}) ,\\
 (x_2(1-x_1x_2)&-(1-x_2x_1)x_2)^{-1}.
\end{split}
\end{equation*}

The careful reader will notice, however, that one of these expressions is not
like the other. If we were to evaluate these expression on tuples of matrices,
there is no pair for which \((x_2(1-x_1x_2)-(1-x_2x_1)x_2)^{-1}\) is defined.
This is an example of a \textbf{degenerate} rational expression. Formally, an nc
rational expression is \textbf{nondegenerate} if there is at least one
\(X \in \MM^{g} \) such that \(r(X)\) is defined.

When seeking to make rational \emph{functions} out of a nondegenerate rational
expression, one encounters significant difficulties. For example,
\[
  x_1-x_1+x_2 ^{-1} x_2-1 \quad \textrm{ and } \quad 0
\]
are syntactically distinct nc rational expressions, have wildly different
domains, yet whenever their domains of evaluation align, they will give the
same evaluation.  With the likes of the Identity Theorem from complex analysis
one would like to say that these are the same function. In light of this, nc
rational functions are defined via equivalence classes. We say two rational
expressions, \(r_1,r_2\), are equivalent if \(r_1(X) = r_2(X)\) whenever both
expressions are defined.

Unfortunately, this introduces a new wrinkle: what is the domain of the
equivalence class? Usually one simply works with the
domain of the representative chosen. With sufficiently well behaved nc rational
functions, we have a realization theorem (given below) that gives us a ``nice'' representative.

Just like the polynomial case, we often consider \emph{matrices} of nc rational
functions. Chapter \ref{ch:ZeroDiv} explores the algebraic geometry of nc
polynomials and rational functions. Thankfully, however, we do not
need any of the in depth theory of rational functions. \cite{heltonFree2013}
contains a slightly broader introduction from an analytical lens while \cite{cohnFree2006}
provides a (more complete) algebraic treatment. The only theorem we will need
comes from the latter:

\begin{theorem}
\label{thm:ratchar}
  For any nondegenerate
  rational expression, \(r\), there is a linear square matrix of polynomials, \(L\), and
  rectangular constants \(b,c\) such that \(r=b^*L ^{-1}c\)---where \(L ^{-1}\) is
  defined wherever \(r\) is defined.
\end{theorem}
