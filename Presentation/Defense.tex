\documentclass[xcolor=dvipsnames, notes]{beamer}

%%%%%%%%%%%%%%%%%%%
% Packages/Macros %
%%%%%%%%%%%%%%%%%%%
\usepackage{amsmath,amsfonts,amssymb,amsthm, mathtools, mathrsfs, faktor, bbm}
\usepackage{wrapfig}
\usepackage{array}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage{enumerate}

\usepackage{import}
\usepackage{xifthen}
\usepackage{pdfpages}
\usepackage{transparent}
\newcommand{\incfig}[1]{%
  \def\svgwidth{0.5\columnwidth}
  \import{./images/}{#1.pdf_tex}
}
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=2pt] (char) {#1};}}


\newcommand{\im}{\mathrm{Im}}
\newcommand{\re}{\mathrm{Re}}
\newcommand{\res}{\mathrm{Res}}
\newcommand{\pv}{\mathrm{p.v.}}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\Log}{Log}
\DeclareMathOperator{\adj}{adj}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\rk}{rk}
\DeclareMathOperator{\divv}{div}

% General shortcuts
\newcommand{\RR}{\mathbb{R}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\HH}{\mathbb{H}}
\newcommand{\MM}{\mathcal{M}}
\newcommand{\Id}{\mathbbm{1}}
\newcommand{\wms}{\textsc{wms} }
\newcommand{\wma}{\textsc{wma} }
\newcommand{\wwlog}{\textsc{wlog} }
\newcommand{\Arg}{\text{Arg}}
\renewcommand\qedsymbol{$\blacksquare$}


%\usepackage[utf8]{inputenc}
\usepackage{pgfpages}

\usepackage{amssymb,latexsym,amsmath,relsize,multicol, amsthm, tikz,tikz-cd, wrapfig, setspace,framed,xcolor,array , array, faktor, listings, mathrsfs , blkarray,booktabs,bigstrut}

\usepackage{soul}
\renewcommand<>{\hl}[1]{\only#2{\beameroriginal{\hl}}{#1}}

% https://tex.stackexchange.com/questions/41683/why-is-it-that-coloring-in-soul-in-beamer-is-not-visible
\makeatletter
\newcommand\SoulColor{%
  \let\set@color\beamerorig@set@color
  \let\reset@color\beamerorig@reset@color}
\makeatother
\SoulColor

\usetikzlibrary{arrows}

\usepackage[framemethod=TikZ]{mdframed}
\mdfsetup{nobreak=true}

\usepackage{stackengine}
\newcommand\xrowht[2][0]{\addstackgap[.5\dimexpr#2\relax]{\vphantom{#1}}}

\usepackage{hhline}

% \usepackage{tikzlings}

%%%%%%%%%%%%%%%%%%
% Beamer Options %
%%%%%%%%%%%%%%%%%%

%\usetheme{Frankfurt}
\usetheme{Antibes}
%\usetheme{AnnArbor}

% Color definitions:
\definecolor{mypurple}{RGB}{179,120,211}
\definecolor{darkpurple}{RGB}{130,98,168}
\definecolor{mygrey}{RGB}{164,167,172}
\definecolor{mygrey2}{RGB}{217,219,220}
\definecolor{fgreen}{RGB}{34,169,75}
\definecolor{gpurple}{RGB}{152,68,158}

%\useoutertheme{infolines} % Alternatively: miniframes, infolines, split
\useinnertheme{circles}
\definecolor{goodgood}{RGB}{127, 23, 52} % UBC Blue (primary)
\definecolor{goodgood1}{RGB}{46, 82, 102} % UBC Blue (primary)
\definecolor{goodgood2}{RGB}{203, 133, 137}
\usecolortheme[named=goodgood]{structure}
%\usecolortheme[named=Mahogany]{structure} % Sample dvipsnames color

%\setbeamercolor{structure}{fg=gpurple} % Title box and slide title box color
%\setbeamercolor{frametitle}{fg=white} % slide title text color
%\setbeamercolor{section in head/foot}{bg=gpurple} % frame background color
%\setbeamercolor{section in head/foot}{fg=white} % frame text color

\setbeamertemplate{navigation symbols}{} % disable navigation icons
\setbeamertemplate{items}[circle]

% Beamer theme font
\usefonttheme{serif}

% % --- page number ---
% \setbeamertemplate{footline}{%
% 	\raisebox{10pt}{\makebox[\paperwidth]{\hfill\makebox[7em]{\normalsize\texttt{\insertframenumber/\inserttotalframenumber}}}}%
% }

% Presenter's note
\setbeameroption{show notes on second screen}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Theorem/Proof Environments %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\renewenvironment{definition}[1][]{\par\medskip\noindent \textbf{Definition:} \textit{#1} \rmfamily \\}{\vspace{4pt}}

\renewenvironment{example}[1][]{\par\medskip\noindent \textbf{Example.} \rmfamily}{\medskip}

\newenvironment{proposition}[1][]{\par\medskip\noindent \textbf{Proposition:} \rmfamily \\}{ \vspace{4pt}}

\newenvironment{mtheorem}[1][]{\begin{mdframed}[roundcorner=10pt] \refstepcounter{theorem}\par\medskip\noindent \textbf{Theorem~\thetheorem.} [#1] \rmfamily \\}{ \vspace{4pt}\end{mdframed}\vspace{-5pt}}
\numberwithin{theorem}{section}

\newenvironment{iproposition}[1][]{\begin{mdframed}[roundcorner=10pt] \refstepcounter{theorem}\par\medskip\noindent \textbf{Proposition~\thetheorem.} [#1] \rmfamily \\}{ \vspace{4pt}\end{mdframed}\vspace{-5pt}}
\numberwithin{theorem}{section}

\newenvironment{conjecture}[1][]{\begin{mdframed}[roundcorner=10pt] \refstepcounter{theorem}\par\medskip\noindent \textbf{Conjecture~\thetheorem.} \rmfamily \\}{ \vspace{4pt}\end{mdframed}\vspace{-5pt}}
\numberwithin{theorem}{section}

\newenvironment{nconjecture}[1][]{\begin{mdframed}[roundcorner=10pt] \refstepcounter{theorem}\par\medskip\noindent \textbf{Conjecture~\thetheorem.(#1)} \rmfamily \\}{ \vspace{4pt}\end{mdframed}\vspace{-5pt}}
\numberwithin{theorem}{section}

\theoremstyle{remark}
\newtheorem*{remark}{Remark}

%%%%%%%%%%%%%%%%%%%
% Custom Commands %
%%%%%%%%%%%%%%%%%%%

\newcommand{\paren}[1]{\left( #1 \right)}
\newcommand{\bracket}[1]{\left[ #1 \right]}
\newcommand{\cparen}[1]{\left\{ #1 \right\}}
\newcommand{\eval}[3]{\left. #1 \right|_{#2}^{#3}}
\newcommand{\abs}[1]{\left| #1 \right|}


%%%%%%%%%%%%
% Document %
%%%%%%%%%%%%

\title{Searching for Holes in the Matrix Universe}
\author{Lucas Kerbs}
\date{Spring 2022}

\begin{document}
\begin{frame}[plain]
  \maketitle
  \note{
    \begin{itemize}
      \item  Eventual goal: lift the tools of algebraic topology to spaces of
            matrices
      \item If we only consider \(2 \times 2\) matrices we can use classical
            theory
      \item The moment we want more than one size, things the classical theory
            breaks down
      \item Today we will develop some \emph{fairly heftly} tools to do just that
      \item Along the way, hopefully I can convince you that this is an
            interesting question.
      \item  To do so, we need to go back to our mathematical roots
    \end{itemize}
  }
\end{frame}

\section{Part I: Objects and Maps}

\begin{frame}
  \begin{center}
    \textcolor{goodgood}{\huge{Part I: Objects and Maps}} \\
    \textcolor{goodgood2}{\large{A Naive Attempt}} \\
  \end{center}
  \note{
    \begin{itemize}
      \item  That's right---objects and maps.
      \item Our Naive attempt involves that looking at lifting functions on
    \(\RR \) or \(\CC \) to accept matrices as their input.
      \item An operator theorist would call this a ``functional calculus''
    \end{itemize}
  }
\end{frame}

\subsection{Functional Calculus}

\begin{frame}{Functional Calculus}
  \onslide<1->{Let \(f \in \RR [x]\) and \(A \in M_k(\CC)\) be self adjoint.}\\
  \onslide<2->{\(A\) is diagonalizable as \(A = U \Lambda U^{*}\)}
  \begin{align*}
    \onslide<3->{f(A) &= a_nA^n + \cdots + a_1A + a_0 I_k  \\}
    \onslide<4->{&= a_n \left( U\Lambda U^* \right) ^n + \cdots + a_1 U\Lambda U^* + a_0 I_k  \\}
    \onslide<5->{&= a_n U\Lambda^n U^* + \cdots + a_1 U\Lambda U^* + a_0 I_k  \\}
    \onslide<6->{&= U \left( a_n\Lambda ^n + \cdots + a_1\Lambda + a_0 I_k \right) U^*  \\}
    \onslide<7->{&= U \left( f(\Lambda) \right) U^*}
  \end{align*}
  \[
   \onslide<8->{f \left( \begin{bmatrix} \lambda_1 &  &  \\  & \ddots &  \\  &  & \lambda_n \end{bmatrix}  \right)}
   \onslide<9->{ =\begin{bmatrix} f(\lambda_1) &  &  \\  & \ddots &  \\  &  & f(\lambda_n) \end{bmatrix}}
  \]
  \note{
    \begin{itemize}
    \item<+-> Polynomials are the most well behaved functions we have, so lets
            start with a polynomial and a self adjoint (\(A=A^*\)) matrix.
    \item<1-> You might say that SA is unnecessary bc we can already evaluate a
            polynomial on a matrix
    \item<+-> Since we are SA, we can diagonalize with unitary matrices.
    \item<+-> Watch what happens when we plug this into our polynomial --- need to be
            careful with the constant term.
    \item<9-> This application along the diagonal is precisely the behavior we
            want to emulate in the functional calculus.
    \end{itemize}
  }
\end{frame}

\begin{frame}
  \onslide<+->{
  Let \(\HH_n\) be the set of \(n\times n\) self adjoint matrices, and define
  \[
    \HH = \bigcup_{n \in \NN } \HH_n, \qquad \MM = \bigcup_{n \in \NN }M_n(\CC)
  \]}
  \onslide<+->{
  \begin{definition}
    Let \(g:[a,b]\to \CC \) and \(D \subset\HH \) denote the set of self adjoint
    matrices with their spectrum in \([a,b]\).}
    \onslide<+->{Then
    \begin{align*}
      g: D &\longrightarrow \MM  \\
         X=U\Lambda U^{*}  &\longmapsto U
                     \begin{bmatrix} g(\lambda_1) & &\\ &\ddots& \\ & & g(\lambda_n) \end{bmatrix}
                    U^*
    .\end{align*}}
  \end{definition}
  \onslide<+->{
  \noindent\textbf{Important:} In this functional calculus, \[g(X\oplus Y) = g(X) \oplus g(Y)\]}
  \note{
    \begin{itemize}
      \item With the polynomial case in mind, we can extend a general function.
         First, a piece of notation
      \item Lets grab a function on the real line and the self adjoint
            matrices with their spectrum in that domain
      \item Then we can lift \(g\) by emulating the behavior of polynomials.
      \item unwrap a self adjoint matrix, apply \(g\) to the diagonal, then wrap
            it back up
      \item Something to notice about this functional calculus---it treats
            direct sums \emph{very} well
      \item This is all well and good, but can we do anything with these new functions?
    \end{itemize}
  }
\end{frame}

\begin{frame}{Directional Derivative}
  \onslide<+->{
  \begin{Definition}[Directional Derivative]
    Fix some \(X \in \HH_n\). The derivative of \(f\) at \(X\) in the direction
    \(H \in M_n(\CC)\) is
    \[
      Df(X)[H] = \lim_{t \to 0} \frac{f(X+tH)-f(X)}{t}
    \]}
  \onslide<+->{
    Alternatively,
    \[
    Df(X)[H] = \left.\frac{df(X+tH)}{dt}\right|_{t=0}
    \]}
  \end{Definition}
  \note{
    \begin{itemize}
      \item We can define a directional derivative---as long as we are careful
            to have the direction in the same ``level-wise'' slice.
      \item Notice that, with some special attention to what operation  we are
            carrying our, this is the exact same definition as classic
            multivariable calculus.
      \item There is another formulation that is (generally) more useful
            for computation
    \end{itemize}
  }
\end{frame}

\begin{frame}{Example: \(g(x)=x^3\)}
  \begin{align*}
    \onslide<+->{g(X+tH) &=}
    \onslide<+->{X^3+ tX^2H +tXHX + t^2XH^2\\
    & \hphantom{= X^3}+ tHX^2 + t^2HXH + t^2H^2X +t^3H^3.}
  \end{align*}
  \onslide<+->{
  From here, we can calculate:}
  \begin{align*}
    \onslide<+->{\frac{d}{dt} g(X+tH) &= X^2H + XHX + 2tXH^2 +HX^2\\
                  &\hphantom{=X^2H} +2tHXH +2tH^2X + 3t^2H^3 }\\
	\vspace{\stretch{2}}
    \onslide<+->{\frac{d^2}{dt^2} g(X+tH) &= 2XH^2+2HXH +2H^2X + 6tH^3 \\}
	\vspace{\stretch{2}}
    \onslide<+->{\frac{d^3}{dt^3} g(X+tH) &= 6H^3.}
	\vspace{\stretch{2}}
  \end{align*}
  \note{
    \begin{itemize}
      \item Now we consider an example. Since \(Df(X)[H]\) is linear, we can
            just work with a single monomial
      \item First we expand \((x+th)^3\)---but we can't use the binomial
            theorem since \(x\) and \(h\) don't commute
      \item Once we expand, we take standard derivatives w.r.t \(t\)---treating
            \(X\) and \(H\) as formal symbols.
    \end{itemize}
  }
\end{frame}

\begin{frame}{Example: \(g(x)=x^3\)}
  \onslide<+->{And so the first 3 directional derivatives are:}
  \begin{align*}
    \onslide<+->{Df(X)[H] &= X^2H + XHX +HX^2\\}
	  \vspace{\stretch{2}} \\
    \onslide<+->{D^{(2)}f(X)[H] &= 2XH^2+2HXH +2H^2X \\}
	  \vspace{\stretch{2}} \\
    \onslide<+->{D^{(3)}f(X)[H] &= 6H^3}
	  \vspace{\stretch{2}}
  \end{align*}
  \note{
    \begin{itemize}
      \item Now all we have to do is set \(t=0\) in the previous expressions and
            we get the first three directional derivatives
      \item Note that they are all in the same direction---mixes derivatives are
            possible but we won't need them.
    \end{itemize}
  }
\end{frame}

% \subsection{Multivarible Functions} %

% \begin{frame}{How should we treat multivariable functions?}
%   \onslide<+->{What about \(f(x,y) = xy \in \CC [x,y]\)? For
%     \(X,Y \in M_n(\CC)\), what is \(f(X,Y)\)?}
%   \[
%     \onslide<+->{XY} \qquad
%     \onslide<+->{YX} \qquad
%     \onslide<+->{\frac{1}{2}(XY+YX)} \qquad
%   \]
%   \onslide<+->{Clearly \(\CC [x,y]\) is the wrong space!}
% \end{frame}

% \begin{frame}{nc Polynomials}
%   \onslide<+->{We must construct a newspace!}
%   \begin{itemize}
%     \item<+-> Let \(x=(x_1, \dots, x_d)\) be a tuple of formal variables.
%     \item<+-> A \textbf{word} in \(x\) is a product of these variables.
%     \begin{itemize}
%        \item<+-> e.g.\ \(x_1x_3x_1x_4^2\qquad x_2^4x_5^3\)
%     \end{itemize}
%     \item<+-> An \textbf{nc polynomial} is a linear combination of words in
%           \(x\) over your favorite field.
%   \end{itemize}
%   \onslide<+->{Let \(\RR \langle x \rangle \) and \(\CC \langle x \rangle \)
%     denote the set of nc polynomials over \(\RR \) and \(\CC \).}
% \end{frame}

% \begin{frame}{Example: \(f(x,y) = x^2-xyx-1 \in \RR \langle x,y \rangle \)}
%   \[
%   \onslide<+->{  X = \begin{bmatrix} 4 &2\\2&2 \end{bmatrix}  \qquad \text{ and } \qquad Y =\begin{bmatrix} 2&0\\0&0 \end{bmatrix}}
%   \]
%   \begin{align*}
%   \onslide<+->{  f(X,Y) &= X^2 - XYX + I_2 \\}
%   \onslide<+->{         &= \begin{bmatrix} 4 &2\\2&2 \end{bmatrix}^2
%              -\begin{bmatrix} 4 &2\\2&2 \end{bmatrix}\begin{bmatrix} 2&0\\0&0 \end{bmatrix}\begin{bmatrix} 4 &2\\2&2 \end{bmatrix}
%              +\begin{bmatrix} 1&0\\0&1 \end{bmatrix} \\}
%   \onslide<+->{         &= \begin{bmatrix} -11&-4\\-4&1 \end{bmatrix}.}
%   \end{align*}
% \end{frame}

% \begin{frame}{Example: \(f(x,y) = x^2-xyx-1 \in \RR \langle x,y \rangle \)}
%   \[
%   \onslide<+->{  X = \begin{bmatrix} 4 &2\\2&2 \end{bmatrix}  \qquad \text{ and } \qquad Y =\begin{bmatrix} 2&0\\0&0 \end{bmatrix}}
%   \]
%   \begin{align*}
%     \onslide<+->{  f(X\oplus X,Y\oplus Y) &=}
%     \onslide<+->{\begin{bmatrix} -11&-4&0&0\\-4&1&0&0 \\ 0&0&-11&-4 \\ 0&0&-4&1 \end{bmatrix} \\}
%     \onslide<+->{&= f(X,Y) \oplus f(X,Y).}
%   \end{align*}
%   \note{
%     \begin{itemize}
%       \item Mention that directional derivatives still work
%       \item nc polynomials also do the unitary thing --- that is worth mentioning
%     \end{itemize}
%   }
% \end{frame}

\subsection{Matrix Universe}

\begin{frame}
  \begin{center}
    \textcolor{goodgood}{\huge{Part I.5: Objects and Maps}} \\
    \textcolor{goodgood2}{\large{A Second Attempt}} \\
  \end{center}
  \note{
    \begin{itemize}
      \item In seeking a more general theory we need to leave the world of this
            ``SA functional calculus'' behind.
      \item Rather than lifting functions to be matrix valued, we will define
            \emph{new} objects that behave like those we just looked at.
    \end{itemize}
  }
\end{frame}

\begin{frame}{Some Definitions}
  \onslide<+->{
  \begin{Definition}
    The \(g\)-dimensional \textbf{Matrix Universe} is
    \[
      \MM^{g} = \bigcup_{n \in \NN } (M_n(\CC))^g
    \]
  \end{Definition}}
  \onslide<+->{By convention, \(X \in \MM^{g}\) is a tuple of like-size matrices}

  \note{
    \begin{itemize}
      \item Definition of the matrix universe --- \(g\) tuples of matrices of
            all sizes
      \item By convetion, tuples are likes size
    \end{itemize}
  }
\end{frame}

\begin{frame}
  \onslide<+->{
  \begin{Definition}
  We say \(D \subset \MM^g\) is a \textbf{free set} if it is closed with respect
  to direct sums and unitary conjugation. That is,}
  \begin{enumerate}
    \item<+-> \(X,Y \in D \) means
          \(X\oplus Y = (X_1\oplus Y_1, \dots, X_g\oplus Y_g)\in D\).
    \item<+-> For \(X,U\) like-size matrices with \(U\) unitary and \(X \in D\),
          then \(U X U^* = \left( UX_1U^*, \dots , UX_g U^*  \right) \in D \).
  \end{enumerate}
  \onslide<+->{For \(D\) a free set, define \(D_n = D \cap (M_n(\CC))^g \)}.
  \end{Definition}
  \note{
    \begin{itemize}
      \item In math we often think about substructures that
            capture the implicit structure our space (subgroup, subspace, etc)
      \item In the nc setting, this is a \emph{free set}, also called nc set
      \item direct sums and unitary conjugation are component wise
      \item If you see a \(D\), you can assume that it is a free set.
      \item A subscript denotes a level-wise slice
      \item Note that this requires a lot of structure on free sets---we want to
            put a name to these structure.
    \end{itemize}
  }
\end{frame}

\begin{frame}
  \onslide<+->{
  \begin{Definition}
    Given \(X \in \MM^{g} \), a tuple of \(n \times n\) matrices, the
    \textbf{fiber} of \(X\) is the set
    \[
      \{X^{\oplus k} \mid  k \in \NN \}.
    \]
  \end{Definition}}
  \onslide<+->{
  \begin{Definition}
    Given \(X \in \MM^{g} \), a tuple of \(n \times n\) matrices, the
    \textbf{envelope} of \(X\) is the set
    \[
      \{ U^* X^{\oplus k} U \mid k \in \NN, U \text{ Unitary} \}.
    \]
  \end{Definition}}
  \note{
    \begin{itemize}
      \item The fiber is all the points ``above'' a given point. Conceptually,
            we imagine identification along the fiber---this will become
            important when we start doing topology
      \item The envelope (which will be less important to us) is the unitary
            smearing of the fiber at each level.
      \item This is a good spot for questions.
    \end{itemize}
  }
\end{frame}

\begin{frame}{A bit of topology}
  \onslide<+->{}
  \onslide<+->{What does it mean for \(D \subset \MM^{g} \) to be open?}
  \begin{itemize}
    \item<+-> There is not a canonical topology
    \item<+-> For us, we will say that \(D\) is open if each \(D_n\) is open.
    \item<+-> Simply connected, connected, bounded, etc.\ are defined similarly.
  \end{itemize}
  \note{
    \begin{itemize}
      \item If we are going to look for holes and build up the algebraic
            topology, we need a point set topology first---so there is a natural
            question.
      \item Bad news: there isn't a natural choice
      \item There are a handful of candidates (fine, fat, free, nc Zariski). I
            wish we had time to go into detail.
      \item For us, free sets are open if their level-wise restriction is open
      \item Other point-set characterizations are similar.
    \end{itemize}
  }
\end{frame}

\begin{frame}{What the natural functions on \(\MM^{g} \)?}
  \onslide<+->{}
  \onslide<+->{
  \begin{Definition}
  A function \(f: D\to \MM^{\hat{g}}\) is called \textbf{free} if
  \begin{enumerate}
    \item \(f(X\oplus Y)= f(X) \oplus f(Y)\)
    \item \(f(U X U^*) = f(U)f(X)f(U^*)\) where \(X\) and \(U\) are like-size
          and \(U\) is unitary.
  \end{enumerate}
  \end{Definition}}
  \onslide<+->{
  \begin{Definition}
  A function \(f: D \to \CC \) is a \textbf{tracial function} if
  \begin{enumerate}
    \item \(f(X\oplus Y) = f(X)+f(Y)\)
    \item \(f(U X U^*) = f(X)\) where \(X\) and \(U\) are like-size
          and \(U\) is unitary.
  \end{enumerate}
  \end{Definition}}
  \note{
    \begin{itemize}
      \item We have our objects, but what are the maps?
      \item Free functions are defined to be anything that behaves like a
            polynomial
      \item tracial functions look like traces
      \item For both of these maps, the directional derivative is defined
            identically as before---but tracial functions get something extra.
    \end{itemize}
  }
\end{frame}

\subsection{Uniqueness of the Gradient}

\begin{frame}
  \begin{Definition}
    Given a tracial function \(f\), the free gradient, \(\nabla f\), is the
    unique free function satisfying
    \[
      \tr \left( H \cdot \nabla f(X) \right) = Df(X)[H],
    \]
    where, if \(A= (A_1, \dots, A_g)\) and \(B=(B_1, \dots, B_g)\) are tuples of
    like-size matrices then \(A \cdot B = \sum_{i=1}^g A_i B_i \).
  \end{Definition}
  \note{
    \begin{itemize}
      \item The \(\nabla\) of a free function is the unique free function
            satisfy this equation---where the * is just like the dot product
      \item Whenever you see tr(*) I want you to think of the inner product---it
            is slightly distinct but it will make a lot of things make more
            sense
      \item Some of you may be hesitant at the fact that I claim \(\nabla\) is
            unique. Why should this be true?
    \end{itemize}
  }
\end{frame}

\begin{frame}{Why should \(\nabla f\) be unique?}
  \onslide<+->{
  \begin{theorem}[Trace Duality]
  Let \(f,g\) be free functions \(\MM^{g} \to \MM^{\tilde{g}} \). If
  \(\tr (H \cdot f) = \tr (H \cdot g)\) for all tuples \(H\), then \(f=g\).
  \end{theorem}}
  \note{
    \begin{itemize}
      \item \(f=g\) whenever the domains overlap
      \item In the vector space setting---with an inner product---this is a
            fairly immediate result. You would show it by picking vectors of all
            0's and a single 1.
      \item You prove this identically---but with coordinate matrices instead of
            coordinate vectors.
      \item Before we look at the algebraic topology, we need to take a brief
            trip to complex variable land
    \end{itemize}
  }
\end{frame}

%\begin{frame}
  %\emph{Proof.}
  %%\onslide<+->{Let \(E_{ij}\) be a matrix of all \(0\)'s with a \(1\) in the
    %\(i,j\) slot. }
%
  %\onslide<+->{Let \(H = (E_{ji}, 0, \dots, 0)\). }
%
  %There isn't time for this proof.
%\end{frame}

\section{Part II: Monodromy}

\begin{frame}
  \begin{center}
    \textcolor{goodgood}{\huge{Part II: Analytic Continuation and Monodromy}} \\
  \end{center}
  \note{
    \begin{itemize}
      \item analytic continuation and monodromy is the link between complex
            analysis and topology.
    \end{itemize}
  }
\end{frame}

\subsection{Analytic Continuation}

\begin{frame}{Analytic Continuation}
  \begin{figure}[h!]
  \centering
    \def\svgwidth{0.7\columnwidth}
    \import{./img/mono/one/}{monodromycurve_one_talk.pdf_tex}
  \end{figure}
  \note{
    \begin{itemize}
      \item Lets say we have some analytic function defined on \(\Omega\) and a
            curve \(\gamma\) taking \(\alpha\) to \(\beta\).
      \item We can expand a power series about \(\alpha\) with some radius of
            convergence. But since \(f\) is analytic, we can expand about some
            any point on \(\gamma\) that is still in the red disk
    \end{itemize}
  }
\end{frame}

\begin{frame}{Analytic Continuation}
  \begin{figure}[h!]
  \centering
    \def\svgwidth{0.7\columnwidth}
    \import{./img/mono/two/}{monodromycurve_two_talk.pdf_tex}
  \end{figure}
  \note{
    \begin{itemize}
      \item But now we have a new radius of convergence! Importantly this will
            agree with the original function on that initial overlap
      \item We can keep doing this!
    \end{itemize}
  }
\end{frame}

\begin{frame}{Analytic Continuation}
  \begin{figure}[h!]
  \centering
    \def\svgwidth{0.7\columnwidth}
    \import{./img/mono/three/}{monodromycurve_three_talk.pdf_tex}
  \end{figure}
  \note{
    \begin{itemize}
      \item Now we have a third power series representation for \(f\)---once
            again, it will agree with our last expasions where those two disks overlap.
      \item As long as \(\gamma\) stays away from any potential poles, we can
            keep doing this all the way to \(\beta\)
    \end{itemize}
  }
\end{frame}

\begin{frame}{Analytic Continuation}
  \begin{figure}[h!]
  \centering
    \def\svgwidth{0.7\columnwidth}
    \import{./img/mono/Final/}{monodromycurve_final_talk.pdf_tex}
  \end{figure}
  \note{
    \begin{itemize}
      \item After repeatedly expanding, we finally have an analytic function at
            \(\beta\)!
      \item As we said, we need \(\gamma\) to avoid poles, but what can we say
            about the uniqueness of the analytic function at \(\beta\)?
    \end{itemize}
  }
\end{frame}


\begin{frame}{Example: Analytically continuing \(\Log z\)}
  \begin{figure}[h!]
  \centering
    \def\svgwidth{0.7\columnwidth}
    \import{./img/log/one/}{monodromylog_one_talk.pdf_tex}
  \end{figure}
  \note{
    \begin{itemize}
      \item Now we have another example: consider the principle branch of the
            complex logarithm.
      \item if we analytically continue along \(\gamma_1\), then we can
            evaluate \(\Log (-1)\).
    \end{itemize}
  }
\end{frame}


\begin{frame}{Example: Analytically continuing \(\Log z\)}
  \begin{figure}[h!]
  \centering
    \def\svgwidth{0.7\columnwidth}
    \import{./img/log/two/}{monodromylog_two_talk.pdf_tex}
  \end{figure}
  \note{
    \begin{itemize}
      \item when we do this, we see that the \(\Log(-1)=-\pi i\).
      \item But what about the other way? What if we continued along a path that
            went through the UHP?
    \end{itemize}
  }
\end{frame}

\begin{frame}{Example: Analytically continuing \(\Log z\)}
  \begin{figure}[h!]
  \centering
    \def\svgwidth{0.7\columnwidth}
    \import{./img/log/three/}{monodromylog_three_talk.pdf_tex}
  \end{figure}
  \note{
    \begin{itemize}
      \item when we do this, we get \(\Log (-1)=\pi i\)! They disagree!
      \item what's even stranger is what happens when we keep going on a circle
            around the origin.
    \end{itemize}
  }
\end{frame}

\begin{frame}{Example: Analytically continuing \(\Log z\)}
  \begin{figure}[h!]
  \centering
    \def\svgwidth{0.7\columnwidth}
    \import{./img/log/four/}{monodromylog_four_talk.pdf_tex}
  \end{figure}
  \note{
    \begin{itemize}
      \item amazingly, when you continue all the way around and compute
            \(f(1)\), you get \(2\pi i\)---not 1.
            \item What is going on here? when are two analytic continuations equal?
    \end{itemize}
  }
\end{frame}



\subsection{Monodromy}

\begin{frame}{When are two analytic continuations equal?}
  \onslide<+->{}
  \onslide<+->{
  \begin{theorem}[Monodromy I]%
    Let \(\gamma_1, \gamma_2\) be two paths from \(\alpha\) to \(\beta\) and
    \(\Gamma_s\) be a fixed-endpoint homotopy between them. If \(f\) can be
    continued along \(\Gamma_s\) for all \(s \in [0,1]\), then the continuations
    along \(\gamma_1\) and \(\gamma_2\) agree at \(\beta\).
  \end{theorem}}
  \onslide<+->{
  \begin{figure}[h!]
  \centering
    \def\svgwidth{0.5\columnwidth}
    \import{./img/homo/}{homotopycurve_talk.pdf_tex}
  \end{figure}}
  \note{
    \begin{itemize}
      \item It is in answering this question that we see the deep link between
            analytic continuation and topology.
      \item Monodromy 1: the paths are homotopic and the function analytically
            continues along all of the intermediate paths, then you are golden!
      \item Note that this tells us that analytic contiuation searches for holes
      \item a picture for those who like that!
      \item when seek to lift this idea to a nc case, it will serve much better
            to consider an alternate characterization
    \end{itemize}
  }
\end{frame}

\begin{frame}{When are two analytic continuations equal?}
  \onslide<+->{
  \begin{theorem}[Monodromy II]%
    Let \(U \subset \CC \) be a disk in \(\CC \) centered at \(z_0\) and
    \(f: U \to \CC \) an analytic function. If \(W\) is
    an open, simply connected set containing \(U\) and \(f\) continues along any
    path \(\gamma \subset W\) starting at \(z_0\), then \(f\) has a unique
    extension to all of \(W\).
  \end{theorem}}
  \note{
    \begin{itemize}
      \item We require simply connected in the big set! Thus, holes get in the
            way of a unique extension.
      \item Obviously we don't have the time to go into explicit detail about
            why, but it turn out that you can realize the fundamental group of
            some open, connected, subset of \(\CC \) simply by looking at the
            analytic continuation of functions!
    \end{itemize}
  }
\end{frame}

\subsection{Free Monodromy}

\begin{frame}{What about the nc case?}
  \onslide<+->{
  Before we look at a free analogue of the monodromy theorem, we need to ask an
  important question: What does it mean for a free function to be analytic?}

  \vspace{\stretch{1}}
  \onslide<+->{\textbf{A}: \(f:D\to \MM^{\hat{g}}\) is analytic if it is
    analytic as a function of each \(D_n\).}

  \vspace{\stretch{1}}
  \onslide<+->{
  \begin{theorem}[Agler, McCarthy (2016)]
    Let \(f:D\to \MM^{\hat{g}}\) be a free function. If \(f\) is locally bounded
    on each \(D_n\), then \(f\) is an analytic free function.
  \end{theorem}}
  \note{
    \begin{itemize}
      \item Now that we have this (very power) theorem from classical complex
            analysis, if we want an nc analogue---what is an ``analytic'' free function.
      \item As with our other characterizations, a free function is analytic if
            it is analytic as a function on each \(D_n\).
      \item Even more surprisingly, we have a *wild* characterization due to
            Agler and McCarthy
      \item This is incredibly powerful---I will let you draw your own
            conclusion as to what is says about the underlying point set topology.
      \item With our question answered, we  can present the free analogue.
    \end{itemize}
  }
\end{frame}

\begin{frame}
  \onslide<+->{
  \begin{theorem}[Free Universal Monodromy, Pascoe 2020]%
    Let \(f\) be an analytic free function defined on some ball \(B \subset D\),
    for \(D\) an open, connected free set.
    If \(f\) analytically continues along every path in \(D\), then
    \(f\) has a unique analytic continuation to all of \(D\).
  \end{theorem}}
  \note{
    \begin{itemize}
      \item all you need to have a unique extension is to continue along every
            path!
      \item The larger set doesn't have to be simply connected! This is huge!
      \item While this theorem is amazing, it is the bearer of bad news
    \end{itemize}
  }
\end{frame}

\begin{frame}{Consequences of Free Monodromy}
  \onslide<+->{}
          \vspace{\stretch{2}}
  \begin{enumerate}
    \item<+-> Free functions can't detect holes!
          \vspace{\stretch{1}}
    \item<+-> If we want a fundamental group governed by analytic continuation,
      we need to look elsewhere.
          \vspace{\stretch{2}}
  \end{enumerate}
  \note{
    \begin{itemize}
      \item There are two major (and related) consequences to free monodromy
      \item First, free functions cannot detect holes via analytic continuation
      \item Therefore, if we want a fundamental group that is governed by
            analytic continuation, we need to look elsewhere
      \item before we transition to the fundamental group, any questions.
    \end{itemize}
  }
\end{frame}

\section{Part III: Homotopy}

\begin{frame}
  \begin{center}
    \textcolor{goodgood}{\huge{Part III: Homotopy}} \\
  \end{center}
  \note{
    \begin{itemize}
      \item In part III we look at two types of fundamental group.
      \item Since free monodromy says that free functions won't give us a
            \(\pi_1\) we start by looking at a fundamental group that is
            divorced from analytic continuation
    \end{itemize}
  }
\end{frame}


\subsection{A First Fundamental Group}

\begin{frame}
  \onslide<+->{
  \begin{definition}
    A continuous function \(\gamma:[0,1]\to D\) \textbf{essentially takes} \(X\) to \(Y\) if
    \begin{align*}
      \gamma(0) = X^{\oplus \ell},& \;\text{ for some \(\ell \in \NN \)}\\
      \gamma(1) = Y^{\oplus k},& \;\text{ for some \(k \in \NN \)}.
    \end{align*}
  \end{definition}}
  \onslide<+->{
  \begin{figure}[h!]
  \centering
    \def\svgwidth{0.7\columnwidth}
    \import{./img/}{essentialpath_talk.pdf_tex}
  \end{figure}}
  \note{
    \begin{itemize}
      \item recall that the fiber of a point in \(\MM^{g} \) is all direct sum
            copies of that point---and futher that we consider everything in the
            fiber somehow ``the same''
      \item An essential path it a traditon path between the fibers!
      \item In order for us to create a group out of these paths, we a
            concatination product.
    \end{itemize}
  }
\end{frame}

\begin{frame}
  \onslide<+->{
  Given \(\gamma\) essentially taking \(X\) to \(Y\) and \(\beta\) taking \(Z\)
  to \(W\), define
  \[
    \gamma\oplus\beta(t) = \begin{bmatrix} \gamma(t)&0\\0&\beta(t) \end{bmatrix}.
  \]}
  \onslide<+->{
  \begin{definition}%
    Let \(\gamma\) and \(\beta\) be paths taking \(X\) to \(Y\) and \(Y\) to \(Z\)
    respectively. We define their product to be the path essentially taking \(X\)
    to \(Z\) given by
    \[
      \beta\gamma(t) =
      \begin{cases}
        \gamma^{\oplus k}(2t) & t \in [0,0.5) \\
        \beta^{\oplus\ell} (2t-1)& t \in [0.5,1]
      \end{cases}
    \]
    where \(k\) and \(\ell\) are positive integers chosen to make
    \(\gamma^{\oplus k}\) and \(\beta^{\oplus \ell}\) like size matrices for each
      \(t \in [0,1]\).
  \end{definition}}
  \note{
    \begin{itemize}
      \item First, we can take the direct sum of paths the exact way that you
            would expect.
      \item To concatenate the paths, the definition is almost identical---first
            you do one path twice as fast, then you do the other
      \item Except you direct sum ``enough'' times to make  it continuous
    \end{itemize}
  }
\end{frame}

\begin{frame}{The Full Fundamental Group}
  For \(D \subset \MM^{g}\) a connected free set, the
  \textbf{full fundamenal group}, \(\pi_1(D)\), is the group of paths essentially taking \(X\)
  to \(X\) up to homotopy equivalence and the relation
  \(\gamma = \gamma^{\oplus k}\).
  \note{
    \begin{itemize}
      \item That was all we needed to create the ``full'' fundamental group.
      \item group of paths up to homotopy equivalence and direct sum of paths
      \item You can show that this is abelian and divisible---but computationally
            we are totally stuck---we don't have any tools to compute \(\pi\; full\)
      \item Instead, we can look at analytic continuation of \emph{tracial}
            functions and see if that can get us anything.
    \end{itemize}
  }
\end{frame}

\subsection{A Second Fundamental Group}

\begin{frame}
  \onslide<+->{
  Let \(D \subset \MM^{g} \) be a connected, open, free set. If there exists a
  nonempty, simply-connected, open, free \(B \subset D\), then we say that \(D\)
  is \textbf{anchored}.}

  \vspace{\stretch{1}}
  \onslide<+->{
  For \(D\) an anchored set, and \(B \subset D\) its anchor, we call a tracial
  function \(f:B\to \CC \) a \textbf{global germ} if it analytically continues
  along every path in \(D\) which starts in \(B\).}

  \vspace{\stretch{1}}
  \onslide<+->{
  For our purposes, we view \(\gamma\) as coupled with its endpoint. Thus, if
  \(\gamma\) essentially takes \(X\) to \(Y\), then
  \[
    f(\gamma) = \frac{1}{k} f(Y^{\oplus k}).
  \]}
  \note{
    \begin{itemize}
      \item Since we are going to look at analytic continuation, we need a place
            to start the functions---this is the anchor
      \item the functions in question are the ``global germs'', which are
            defined on the anchor but analytically along any path in the free set.
      \item to make sense of \(f(\gamma)\)---analytically continue along
            \(\gamma\), compute \(f\) of the endpoint, then normalize
    \end{itemize}
  }
\end{frame}

\begin{frame}{Trace Equivalence}
  \onslide<+->{
  \begin{definition}
    Let \(B \subset D\) be an anchor and fix \(X \in B\). If \(\gamma\) and
    \(\beta\) both essentially take \(X\) to \(Y\), we say they are
    \textbf{trace equivalent} if, for every global germ \(f\) and every path
    \(\delta\) taking \(Y\) to \(Z\), \[f(\delta\gamma)=f(\delta\beta).\]}

    \onslide<+->{
    That is, trace equivalent paths are those which cannot be told apart via
    analytic continuation of global germ.
  \end{definition}}
  \note{
    \begin{itemize}
      \item For two paths essentially taking \(X\) to \(Y\), we say they are
            tr eq if for all global germs \(f(\delta\gamma)=f(\delta\beta)\).
      \item Both of these are computing \(f(Z)\), but with different analytic
            contuations.
      \item Note that (from classical monodromy) this captures endpoint homotopy
            and the direct sum identity.
    \end{itemize}
  }
\end{frame}

\begin{frame}{The Tracial Fundamental Group}
  \onslide<+->{
  Let \(D \subset \MM^{g}\) be an anchored space with \(B\) is anchor.
  For \(X \in B\) define
  \(\pi_1^{\textrm{tr}}(D)\) to be the group of trace equivalent paths
  essentially taking \(X\) to \(X\).}

  \vspace{\stretch{1}}
  \onslide<+->{Computationally, we are still stuck.}

  \vspace{\stretch{2}}
  \note{
    \begin{itemize}
      \item This is our second fundamental group---entirely goverened by the
            analytic continuation of global germs.
      \item Since tr eq captures fixed end pt homotopy and the direct sum
            idenity, \(\pi_1^{\tr}\) is a quotient of \(\pi_1\)
      \item There is still a big downside to this definition---it gets us no
            closer to computation.
    \end{itemize}
  }
\end{frame}

\section{Part IV: Cohomology}%

\begin{frame}
  \begin{center}
    \textcolor{goodgood}{\huge{Part IV: Cohomology}} \\
  \end{center}
  \note{
    \begin{itemize}
      \item Cohomology is going to help us a lot when it comes to
            characterizing---and eventually computing \(\pi_1^{\tr}\).
      \item Just a note, this is by far the most technical section---so bear
            with me.
      \item before we jump into the particular cohomological theory we are going
            to be using, lets speedrun a review of cohomology.
    \end{itemize}
  }
\end{frame}

\subsection{A Short Review of Cohomology}

\begin{frame}
  \onslide<+->{}
  \onslide<+->{Traditional homology considers a complex of the form
  \[
    \cdots
    \xleftarrow{\partial_{n-1}}
    C_{n-1}
    \xleftarrow{\partial_{n}}
    C_{n}
    \xleftarrow{\partial_{n+1}}
    C_{n+1}
    \xleftarrow{\partial_{n+2}}
    \cdots
  \]}
  \onslide<+->{
  While cohomology considers a dual complex
  \[
    \cdots
    \xrightarrow{d_{n-2}}
    C^{n-1}
    \xrightarrow{d_{n-1}}
    C^{n}
    \xrightarrow{d_{n}}
    C^{n+1}
    \xrightarrow{d_{n+1}}
    \cdots
  \]}

  \vspace{\stretch{1}}

  \onslide<+->{In general, \(C^k\) is a group of functions into some abelian
    group.}

  \vspace{\stretch{1}}

  \onslide<+->{The \(k\)-th cohomology group is
  \[
    H^k= \frac{\textrm{ker}\, d_i}{\textrm{Im}\, d_{i-1}}
  \]}
  \vspace{\stretch{1}}
  \note{
    \begin{itemize}
      \item In traditional homology, the boundarmy homomorphisms
            \emph{decrease the index}.
      \item For cohomology, the boundary morphism go the other way---the index
            \emph{increases}
      \item Generally, we consider the chain groups to be groups of functions
            into some abelian group, but that isn't always the case
      \item once you have this co-chain complex, you compute the cohomology
            groups exactly the same way you did before.
      \item the \textbf{kernel} of one map mod the \textbf{image} of the
            previous one.
    \end{itemize}
  }
\end{frame}

\subsection{Tracial Cohomology}

\begin{frame}
  \onslide<+->{
  Let \(D\) be an anchored set. Denote the set of
  (globally defined)
  tracial functions on \(D\) by \(\mathcal{T}(D)\) and the set of free functions by
  \(\mathcal{F}(D)\).}
  \onslide<+->{
  For \( f \in \mathcal{T}(D)\), \(\nabla f \in \mathcal{F}(D)\)---so we have the
  beginnings of a chain complex!}
  \onslide<+->{
  \[
    0 \rightarrow \mathcal{T}(D) \xrightarrow{\nabla} \mathcal{F}(D) \rightarrow \cdots.
  \]}
  \note{
    \begin{itemize}
      \item Lets build a complex! We start with two sets of functions.
      \item Since the gradient of a \textbf{tracial} function is a free one, we
            have the first map!
      \item Now this isn't particularly impressive, it is (almost) enough if we
            are careful.
    \end{itemize}
  }
\end{frame}

\begin{frame}
  \onslide<+->{
  \[
    0 \rightarrow \mathcal{T}(D) \xrightarrow{\nabla} \mathcal{F}(D) \rightarrow \cdots.
  \]}

  \onslide<+->{
  A free function \(g: D \to \MM^{g} \) is \textbf{exact} if there exists a
  tracial function \(f: D \to \CC \)
  such that \(\nabla f = g\).}

  \vspace{\stretch{1}}
  \onslide<+->{
  A free function \(g: D \to \MM^{g} \) is \textbf{closed} if
  \[
    \tr \left( K \cdot Dg(X)[H] \right) = \tr \left( H \cdot Dg(X)[K] \right)
  \]
  for all directions \(H,K\).
  }

  \vspace{\stretch{1}}
  \onslide<+->{
  \begin{definition}
    The \textbf{first tracial cohomology group} is the vector space of closed free
    functions moduluo the exact free function. We write \(H^1_{\textrm{tr}}(D) \).
  \end{definition}
  }
  \note{
    \begin{itemize}
      \item Since we are looking at \(\pi_1\), we need to create
            \(H^1\)---which is the homology of *this* part.
      \item The image of \(\nabla \) is very easy---a free function is exact if
            it there is some \emph{global} tracial function such that \(\nabla f=g\)
      \item The kernel is a bit harder---we say closed if it follows this
            condition.
      \item if you view tr(*) as the inner product and \(Dg(X)[H]\) as something
            like the jacobian evaluated on a direction, then this is just the
            classical condition of a closed!
      \item Now we define the first \emph{tracial} fundamental group as the
            closed functions mod the exact ones
    \end{itemize}
  }
\end{frame}

\begin{frame}{What about global germs?}
  \begin{itemize}
    \item<+-> For \(f: B \to \CC \) a global germ, since \(f\) analytically
          continues along every path, so does \(\nabla f\).
    \item<+-> Free Monodromy means that \(\nabla f\) has a global extension.
    \item<+-> \textbf{Important:} If \(f\) is a global germ, then \(\nabla f\)
          is not necessarily exact since \(\mathcal{T}(D)\) is the set of
          tracial functions defined on \emph{all of} \(D\).
  \end{itemize}
  \note{
    \begin{itemize}
      \item Now I want to pause for a second and think about the global germs
            that govern \(\pi_1^{\tr}\)---where do they fit in with everything?
      \item Since \(f\) continues along every path, so does \(\nabla f\).
      \item By free monodromy then, \(\nabla f\) has a unique extension to the
            whole space---it is a global free function.
      \item But! \(\nabla f\) is *not* necessarily exact bc \(f\) doesn't
            necessarily have a global extension.
    \end{itemize}
  }
\end{frame}

\subsection{Injecting into \(\CC \)}

\begin{frame}
  \vspace{\stretch{1}}
  \onslide<+->{
  \textbf{Goal:} Show that \(\pi_1^{\tr}(D)\) injects into \(\CC \).}

  \vspace{\stretch{1}}
  \onslide<+->{
  \begin{lemma}[Kerbs]%
    Let \(D\) be an anchored set. For any \(\alpha,\beta \in \pi_1^{\tr}(D)\) and
    global germ \(f\),
    \[
      f(\alpha\beta) - f(\alpha) = f(\beta) - f(\tau)
    \]
    where \(\tau\) is the constant path.
  \end{lemma}}
  \vspace{\stretch{1}}
  \note{
    \begin{itemize}
      \item Before we continue, I want to give a look at the light at the end of
            the tunnel. We are going to use the tracial cohomology group to show
            that \(\pi_1^{\tr}\) injects in \(\CC \) and prove a major structure
            theorem.
      \item Like any good theorem, it all depends on some technical lemma---here
            is ours
      \item So what is this saying? \(f(\alpha\beta)-f(\alpha)\) measure how
            analytic continuation changes the value of \(f(\alpha)\). With this
            in mind, it isn't hard to believe the lemma.
    \end{itemize}
  }
\end{frame}

\begin{frame}
  \onslide<+->{
  For \(D\) an anchored set, \(X \in B_1\) the base point, \(f\) a global germ,
  and \(\gamma \in \pi_1^{\tr}(D)\), define
  \[
    c^f(\gamma) = f(\gamma)-f(\tau)
  \]}

  \onslide<+->{\(c^f\) gives us a homomorphism into \(\CC \)!}
  \begin{align*}
    \onslide<+->{c^f(\gamma_1\gamma_2) &= f(\gamma_1\gamma_2) - f(\tau) \\}
               \onslide<+->{&= f(\gamma_1\gamma_2) - f(\gamma_1) + f(\gamma_1) -f(\tau) \\}
               \onslide<+->{&= f(\gamma_2) - f(\tau) + f(\gamma_1) -f(\tau) \\}
               \onslide<+->{&= c^f(\gamma_2) + c^f(\gamma_1).}
  \end{align*}
  \note{
    \begin{itemize}
      \item Lets define \(c^f(\gamma)\) to be the measure of how analytic
            continuation along \(\gamma\) changes \(f\).
      \item What is amazing is that \(c^f(\gamma)\) is a homomorphism into \(\CC \)
      \item From the definition, we use the ol' ``add, substract'' trick and
            then our technical lemma
      \item In fact, \(c^f(\gamma)\) gives us something stronger than a
            homomorphism into \(\CC \).
    \end{itemize}
  }
\end{frame}

\begin{frame}
  \vspace{\stretch{1}}

  \onslide<+->{
  \begin{lemma}[Pascoe, 2020]
    The map
    \begin{align*}
	    \Phi:  \pi_1^{\tr}(D)
      &\longrightarrow \prod_{\substack{\nabla f \in H^1_{\tr}(D) \\ f \textrm{ a global germ}}}\CC  \\
       \gamma &\longmapsto \prod c^f(\gamma)
    \end{align*}
    is an injective homomorphism.
  \end{lemma}}

  \vspace{\stretch{1}}
  \onslide<+->{So \(\pi_1^{\tr}(D)\) is commutative and torsion free!}

  \vspace{\stretch{1}}
  \note{
    \begin{itemize}
      \item So this lemma claims to be an injective homomorphism, but what it
            going on with the map?
      \item We map \(\pi_1\) into a product of \(\CC \)'s with one for every
            unique image of a global germ under \(\nabla\).
      \item To get injectivity, you do need that many products of \(\CC \). You
            end up using a very similar arguement to what we did before of
            ``add, subtract'' then using the technical lemma.
      \item This gives us two really important characterizations of
            \(\pi_1^{\tr}\)---we are commutative *and* torsion free
    \end{itemize}
  }
\end{frame}

\subsection{Characterizing \(\pi_1^{\tr}(D)\)}

\begin{frame}{\(\pi_1^{\tr}(D)\) is divisible}
  \onslide<+->{}
  \onslide<+->{
  For any \(\gamma \in \pi_1^{\tr}(D)\),
  \[
    \gamma\oplus\tau = \tau\oplus\gamma.
  \]}

  \vspace{\stretch{1}}
  \onslide<+->{
  Why?
  \[
    H(t,\theta)  = \begin{bmatrix} \cos \theta & \sin \theta \\ -\sin \theta& \cos \theta \end{bmatrix}
    \left( \gamma \oplus \tau \right)
   \begin{bmatrix} \cos \theta & \sin \theta \\ -\sin \theta& \cos \theta \end{bmatrix}^*
  \]
  is a homotopy between the paths.}
  \vspace{\stretch{1}}
  \note{
    \begin{itemize}
      \item But we can go further, and show that \(\pi_1^{\tr}\) is divisible.
            Since we are writing our group multiplicatively, this is equivalent
            to saying we can take \(n\)-th roots
      \item The first thing we need is that, in \(\pi_1\) you can direct sum a
            \(\tau\) on either side. All you need for this is a fixed end pt
            homotopy of some rotation matrices
      \item so if we have a path on one side of a direct sum and an identity on
            the other, we are free to flip the order---this is how we will show divisibility
    \end{itemize}
  }
\end{frame}

\begin{frame}
\begin{align*}
  \small
\onslide<+->{  \gamma &= \underbrace{\begin{bsmallmatrix} \gamma &&&\\ &\gamma&\\&&\ddots\\&&&\gamma\end{bsmallmatrix}}_{k\textrm{-times}}\\}
    \onslide<+->{&=\begin{bsmallmatrix} \gamma &&&\\ &\tau&\\&&\ddots\\&&&\tau\end{bsmallmatrix}
      \begin{bsmallmatrix} \tau &&&\\ &\gamma&\\&&\ddots\\&&&\tau\end{bsmallmatrix}\cdots
      \begin{bsmallmatrix} \tau &&&\\ &\tau&\\&&\ddots\\&&&\gamma\end{bsmallmatrix}\\}
    \onslide<+->{&=\begin{bsmallmatrix} \gamma &&&\\ &\tau&\\&&\ddots\\&&&\tau\end{bsmallmatrix}
      \begin{bsmallmatrix} \gamma &&&\\ &\tau&\\&&\ddots\\&&&\tau\end{bsmallmatrix}\cdots
      \begin{bsmallmatrix} \gamma &&&\\ &\tau&\\&&\ddots\\&&&\tau\end{bsmallmatrix}\\}
    \onslide<+->{&=\begin{bsmallmatrix} \gamma &&&\\ &\tau&\\&&\ddots\\&&&\tau\end{bsmallmatrix}^k}
\end{align*}
\note{
  \begin{itemize}
    \item Under trace equivalence, we can direct sum as many \(\gamma\)'s we
          want, so we grab \(k\) of them
    \item Since diagonal, we can separate this to be a single \(\gamma\) and a
          whole lot of \(\tau\)'s
    \item But now we can go through and flip these one by one to put the
          \(\gamma\) first
    \item If we collect terms, we get a formula for \(k\)-th roots!
  \end{itemize}
}
\end{frame}

\begin{frame}
  \begin{theorem}[Pascoe 2020]
    For \(D\) an anchored free set, \(\pi_1^{\tr}(D)\) is a torsion free,
    abelian, divisible group. That is,
    \[
      \pi_1^{\tr}(D) \simeq \bigoplus_{i \in I} \QQ = \QQ ^I
    \]
    for some set \(I\).
  \end{theorem}
  \note{
    \begin{itemize}
      \item Putting this all together, we know that \(\pi_1^{\tr}\) is abelian,
            divisible, and torsion free. Thanks to a ``fundamental structure
            theorem'' this means that \(\pi_1^{\tr}\) is isomorphic to some
            number of copies of \(\QQ \)!
      \item ``But I promised we would be able to compute! This is just a structure theorem!''
    \end{itemize}
  }
\end{frame}

\section{Computing \(\pi_1^{\tr}(D)\)}

\begin{frame}
  \begin{center}
    \textcolor{goodgood}{\huge{Part V: Computing \(\pi_1^{\tr}(D)\)}} \\
  \end{center}
  \note{
    \begin{itemize}
      \item In classical theory, we have VC and MV---neither of these exist
            here. But we have something better: universal properties.
    \end{itemize}
  }
\end{frame}

\subsection{The Direct Limit Approach}

\begin{frame}
  \onslide<+->{
  Let \(D\) be an anchored, path connected set such that each \(D_n\) is
  nonempty and choose an anchor \(B \subset D\) such that each \(B_n\) is also
  nonempty. \\}


  \vspace{\stretch{1}}
  \onslide<+->{Let \(\pi_1^{\tr}(D)_n\) is the subgroup of paths in \(D_n\).
    Note that \(\pi_1^{\tr}(D)_n\) is a quotient of \(\pi_1(D_n)\).\\}


  \vspace{\stretch{1}}
  \onslide<+->{There is a natural inclusion
  \begin{align*}
      \pi_1^{\tr}(D)_n&\lhook\joinrel\longrightarrow  \pi_1^{\tr}(D)_{kn}\\
                  \gamma&\longmapsto \gamma^{\oplus k}
  \end{align*}
  for all \(k\).}
  \vspace{\stretch{1}}
  \note{
    \begin{itemize}
      \item Here are our niceness condition for our computation to work.
      \item as before, the \(_n\) denotes restricting to the \(n\times n\) level.
      \item We are a quotient bc these are all paths in \(D_n\) but there might
            be some paths that are distinct in \(\pi_1(D_n)\) but not in \(\pi_1^{\tr}(D)_n\).
      \item Via direct sums, we have inclusion into any level with contains
            \(n\) as a factor
    \end{itemize}
  }
\end{frame}

\begin{frame}
  \vspace{\stretch{2}}
  \onslide<+->{
  Now consider the chain of inclusions:
  \[
    \pi_1^{\tr}(D)_1 \hookrightarrow
    \pi_1^{\tr}(D)_2 \hookrightarrow
    \pi_1^{\tr}(D)_6 \hookrightarrow \cdots \hookrightarrow
    \pi_1^{\tr}(D)_{n!} \hookrightarrow \cdots
  \]}

  \vspace{\stretch{1}}
  \onslide<+->{The limit of this sequence isomorphic to \(\pi_1^{\tr}(D)\)!}

  \vspace{\stretch{2}}
  \note{
    \begin{itemize}
      \item starting at the scalar level, lets run through all of the natural
            inclusions, muliplying by the next positive integer each time.
      \item If you're familiar with direct limits, its not hard to see that
            \(\pi_1^{\tr}\) is the direct limit of this sequence
      \item if you have no idea what that means, just think of it as the group
            that naturally lives at the ``end'' of this sequence.
      \item for domains that if within our niceness condition, this is exactly
            how we compute \(\pi_1^{\tr}\).
    \end{itemize}
  }
\end{frame}

\subsection{An Example}

\begin{frame}{Example: \(\pi_1^{\tr}(GL)\)}
  \vspace{\stretch{1}}
  \onslide<+->{Let \(GL = \bigcup_{n \in \NN }GL_n(\CC)\).}

  \vspace{\stretch{1}}
  \onslide<+->{ \(GL_1(\CC) = \CC \setminus \{0\} \). Since
    \(\pi_1(GL_1) \simeq \ZZ \),
    \(\pi_1^{\tr}(GL)_1 \simeq \ZZ \) as well.}

  \vspace{\stretch{1}}
  \onslide<+->{Inclusion into \(\pi_1^{\tr}(GL)_2\) picks up square roots. If
  \(\gamma \in \pi_1^{\tr}(GL)_1\), then
  \[
    \begin{bmatrix} \gamma&\\&\tau \end{bmatrix} \in \pi_1^{\tr}(GL)_2.
  \]
  }

  \onslide<+->{Thus, \(\pi_1^{\tr}(GL)_2 \simeq \ZZ \left[\frac{1}{2}\right].\)}
  \vspace{\stretch{1}}
  \note{
    \begin{itemize}
      \item Now we can proceed with an actual example! \(GL\) is all invertable
            matrices of all sizes.
      \item using the direct limit approach, we want look at the 1x1 slice.
      \item the determinant a scalar is itself, so our set is
            \(\CC \setminus \{0\} \), which has fundamental group \(\ZZ \). The
            only way to be at torsion free subgroup/quotient of \(\ZZ \) is just
            to be \(\ZZ \).
      \item When we go the second level, we pick up square roots. It is not too
            difficult to show that we don't get anything else, so we get
            \(\ZZ [1 /2]\)
    \end{itemize}
  }
\end{frame}

\begin{frame}
  \vspace{\stretch{1}}
  \onslide<+->{Similarly, inclusion into \(\pi_1^{\tr}(GL)_{3!}\) picks up cube
    roots:
  \[
    \pi_1^{\tr}(GL)_6 \simeq \ZZ \left[\frac{1}{2}, \frac{1}{3}\right]
  \]
  }

  \vspace{\stretch{1}}
  \onslide<+->{In the \(n\)-th inclusion, we pick up \(n\)-th roots and so we adjoin \(\frac{1}{n}\) to the
    preceding group. Therefore,
  \[
    \pi_1^{\tr}(GL) \simeq \ZZ \left[\frac{1}{2},\frac{1}{3},\frac{1}{4}, \dots\right]}
    \onslide<+->{\simeq \QQ.}
  \]

  \vspace{\stretch{1}}
  \note{
    \begin{itemize}
      \item For the same reason, when we include into our next one, we get cube
            roots and adjoin \(1 / 3\)
      \item continuing on in the same fashion, we get \(\QQ \)!
    \end{itemize}
  }
\end{frame}

\begin{frame}
  \begin{center}
    \textcolor{goodgood}{\huge{Thank You!}} \\
  \end{center}
  \note{
    \begin{itemize}
      \item That's it! The algebraic topology of free sets is in its
            infancy but results look promising!
      \item Thank you!
    \end{itemize}
  }
\end{frame}



\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-engine: luatex
%%% End:
